In the presented thesis, we studied the problem of multi-article news comment summarization and focused on the challenging problem of clustering comments by topic, which is an essential component of many extractive summarization systems. To the best of the author's knowledge, it is novel in summarizing comments under multiple articles in a topic-driven manner. For the task of topic clustering, three models were compared. The Hierarchical multi-Dirichlet Process (HMDP) topic model was introduced, because it allows context inclusion to tackle data sparsity in comments. It was compared to the Markov Cluster Algorithm (MCL) using the parametric topic model Latent Dirichlet Allocation (LDA) as baseline. \par
Evaluation was restricted to topic clustering and carried out based on a gold-standard with comments grouped by topic. A process to form grouped gold standards based on a number of seed comments to which randomly sampled comments are clustered was outlined. In accordance to this process, 100 of 6195 comments in a used dataset were annotated. This allowed an evaluation using a large corpus without complete annotation. Nevertheless, this approach is limited due to a differing number of clusters in gold standard and clustered corpus. To counteract, precision was emphasized over recall and the clustering structure manually observed. It turned out that the HMDP performed best by F-measure, followed by the MCL and LDA when using both only the gold standard and the entire dataset for training. Moreover, it provided the most sensible clustering structure. The thesis that context inclusion can improve topic modeling and clustering in sparse comments is, thus, supported. Three different types of contexts were evaluated, namely the thread-relationship, article-relationship and timestamp of a comment.
The thread-relationship was most influential in topic modeling as shown by an inspection of the context weights inferred by the HMPD model. Furthermore, our evaluation highlighted drawbacks of held-out likelihood measurements for topic models, since Perplexity did not show any performance differences between HMDP and LDA, while gold standard-based evaluation showed significant differences. \par
An unsupervised approach to topic clusters labeling was outlined which utilizes n-grams extracted from the comments and their importance in accordance to the topic-word distribution of topic models. With sufficient data, this method yielded descriptive labels which, nevertheless, was not validated with a formal evaluation. Furthermore, the ranking algorithm Maximal Marginal Relevance was used to maximize topic-relevance of summary comments. The summary generation results in a violin plot of sentiment and the highest ranked comments of negative and positive sentiment extracted for each of the most important topics. \par
The results of this thesis open many possibilities for future work. 
The steps of ranking, cluster labeling and visualization could be evaluated formally for the summarization of comments of multiple articles, which was not included in this thesis. Furthermore, methods of opinion summarization were included based on sentiment analysis and can be explored further. Comment topics typically have a large temporal nature, where opinion evolves over time. This can be included included in a summary as is indicated in \hyperref[topic_evo]{Appendix}. The applicability of the results is generally not restricted to news article comments, as well. It would be interesting to see, how they translate to other sorts of textual data in context such as Tweets. A summary, where multiple social input streams are combined would be an interesting challenge, as well. \par
The topic clustering methods of this thesis can be developed further, as well. New context spaces can be explored with the HMDP such as a reply-relationship or geospatial context spaces of e.g. geographically close comments, which could not be included based on this thesis's dataset. Moreover, hyperparameter optimization and an optimization of the number of context clusters for timely and geospatial contexts with e.g. an Infinite Gaussian mixture model \footnote{as recommended by Kling in \url{https://github.com/ckling/promoss}} can be investigated. The MCL can be optimized, as well, by tackling data sparsity in the similarity measurement between comments by including external knowledge bases, for example.
\clearpage